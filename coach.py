# file: coach.py (FINAL, BATCHED MCTS VERSION)
import torch
import torch.nn.functional as F
import torch.optim as optim
import queue
import threading
import numpy as np
import tqdm
import random
import os
import re
from torch.optim.lr_scheduler import CosineAnnealingLR

from neural_net import ExtendedConnectNet
from config import args
import cpp_mcts_engine
from collections import deque  # <-- æ–°å¢è¿™ä¸€è¡Œ
import platform
import ctypes


def get_augmented_data(state, policy, board_size):
    """
    å¯¹å•ä¸ªè®­ç»ƒæ ·æœ¬è¿›è¡Œ8ç§å¯¹ç§°å˜æ¢çš„æ•°æ®å¢å¼ºã€‚
    :param state: Numpy array, å½¢çŠ¶ä¸º (6, board_size, board_size)
    :param policy: Numpy array, å½¢çŠ¶ä¸º (board_size * board_size,)
    :param board_size: æ£‹ç›˜å¤§å°
    :return: ä¸€ä¸ªåŒ…å«8ä¸ª (state, policy) å…ƒç»„çš„åˆ—è¡¨
    """
    augmented_data = []

    # å°†ç­–ç•¥å‘é‡å˜å›äºŒç»´ï¼Œæ–¹ä¾¿æ“ä½œ
    policy_2d = policy.reshape(board_size, board_size)

    # 8ç§å¯¹ç§°å˜æ¢
    for i in range(1, 5):  # æ—‹è½¬ 0, 90, 180, 270 åº¦

        # å˜æ¢ State
        augmented_state = np.rot90(state, i, axes=(1, 2))
        # å˜æ¢ Policy
        augmented_policy_2d = np.rot90(policy_2d, i)

        # åŸå§‹æ—‹è½¬ç‰ˆæœ¬
        augmented_data.append((augmented_state.copy(), augmented_policy_2d.flatten()))

        # æ°´å¹³ç¿»è½¬åå†æ—‹è½¬çš„ç‰ˆæœ¬
        flipped_state = np.flip(augmented_state, axis=2)
        flipped_policy_2d = np.flip(augmented_policy_2d, axis=1)
        augmented_data.append((flipped_state.copy(), flipped_policy_2d.flatten()))

    return augmented_data


# å®šä¹‰ä¸€ä¸ªä»…åœ¨Windowsä¸‹ç”Ÿæ•ˆçš„å†…å­˜æ¸…ç†å‡½æ•°
def clear_windows_memory():
    if platform.system() == "Windows":
        try:
            # è°ƒç”¨Windows APIæ¥å¼ºåˆ¶æ¸…ç†å½“å‰è¿›ç¨‹çš„å†…å­˜å·¥ä½œé›†
            ctypes.windll.psapi.EmptyWorkingSet(ctypes.windll.kernel32.GetCurrentProcess())
            print("[System] Windows memory working set has been cleared.")
        except Exception as e:
            print(f"[System] Failed to clear Windows memory working set: {e}")


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# ====================== æ™ºèƒ½æ¨¡å‹ç®¡ç†å‡½æ•° (å…¨æ–°) ======================

def transfer_weights(new_model, path_to_old_weights):
    """
    å°†æ—§æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯è¾ƒå°çš„æ¨¡å‹ï¼‰çš„æƒé‡åŠ è½½åˆ°æ–°æ¨¡å‹ä¸­ã€‚
    åªåŠ è½½å±‚åå’Œæƒé‡å½¢çŠ¶éƒ½åŒ¹é…çš„å±‚ã€‚
    """
    print(f"--- å¯åŠ¨è¿ç§»å­¦ä¹ ï¼Œä» '{path_to_old_weights}' åŠ è½½æƒé‡ ---")
    old_state_dict = torch.load(path_to_old_weights, map_location=torch.device('cpu'))
    new_model_state_dict = new_model.state_dict()
    loaded_count = 0
    skipped_count = 0
    for name, param in old_state_dict.items():
        if name in new_model_state_dict and new_model_state_dict[name].shape == param.shape:
            new_model_state_dict[name].copy_(param)
            loaded_count += 1
        else:
            skipped_count += 1
    new_model.load_state_dict(new_model_state_dict)
    print(f"--- è¿ç§»å­¦ä¹ å®Œæˆã€‚æˆåŠŸè¿ç§» {loaded_count} ä¸ªå±‚ï¼Œè·³è¿‡ {skipped_count} ä¸ªä¸å…¼å®¹å±‚ã€‚ ---")
    return new_model


def save_model(model, epoch, args):
    """
    ä¿å­˜æ¨¡å‹ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆå¸¦ç»“æ„ä¿¡æ¯çš„æ–‡ä»¶å (åŒæ—¶ä¿å­˜ .pth å’Œ .pt)
    """
    # vvvvvv ä»argsè·å–é€šé“æ•°å¹¶æ„å»ºæ–°çš„æ–‡ä»¶å vvvvvv
    num_channels = args['num_channels']
    base_filename = f"model_{epoch}_{args['num_res_blocks']}x{args['num_hidden']}_{num_channels}c"
    # ^^^^^^ ä»argsè·å–é€šé“æ•°å¹¶æ„å»ºæ–°çš„æ–‡ä»¶å ^^^^^^
    model_path_pth = f"{base_filename}.pth"
    model_path_pt = f"{base_filename}.pt"

    torch.save(model.state_dict(), model_path_pth)
    print(f"æ¨¡å‹ {model_path_pth} å·²ä¿å­˜ã€‚")

    model.eval()
    # vvvvvv ä½¿ç”¨argsä¸­çš„é€šé“æ•°åˆ›å»ºç¤ºä¾‹è¾“å…¥ vvvvvv
    example_input = torch.rand(1, num_channels, args['board_size'], args['board_size']).to(device)
    # ^^^^^^ ä½¿ç”¨argsä¸­çš„é€šé“æ•°åˆ›å»ºç¤ºä¾‹è¾“å…¥ ^^^^^^
    try:
        traced_script_module = torch.jit.trace(model, example_input)
        traced_script_module.save(model_path_pt)
        print(f"TorchScriptæ¨¡å‹ {model_path_pt} å·²æˆåŠŸå¯¼å‡ºã€‚")
    except Exception as e:
        print(f"ã€é”™è¯¯ã€‘å¯¼å‡ºTorchScriptæ¨¡å‹å¤±è´¥: {e}")


# åœ¨ coach.py ä¸­ï¼Œç”¨ä¸‹é¢çš„æ–°å‡½æ•°æ›¿æ¢æ—§çš„ find_latest_model_file å‡½æ•°

def find_latest_model_file():
    """
    æŸ¥æ‰¾æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶ï¼Œå½“è½®æ¬¡ï¼ˆepochï¼‰ç›¸åŒæ—¶ï¼Œé€‰æ‹©æœ€è¿‘è¢«ä¿®æ”¹çš„æ–‡ä»¶ã€‚
    """
    path = "."
    max_epoch = -1
    latest_file_info = None
    latest_mtime = -1  # ç”¨äºè®°å½•æœ€æ–°æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´

    # vvvvvv æ­£åˆ™è¡¨è¾¾å¼ç°åœ¨åªåŒ¹é… .pth æ–‡ä»¶ vvvvvv
    pattern = re.compile(r"model_(\d+)_(\d+)x(\d+)_(\d+)c\.pth")
    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    for f in os.listdir(path):
        match = pattern.match(f)
        if match:
            epoch = int(match.group(1))
            full_path = os.path.join(path, f)
            mtime = os.path.getmtime(full_path)

            # å¦‚æœè½®æ¬¡æ›´å¤§ï¼Œæˆ–è€…è½®æ¬¡ç›¸åŒä½†æ–‡ä»¶æ˜¯æ›´æ–°çš„ï¼Œåˆ™æ›´æ–°ä¸ºæœ€æ–°æ¨¡å‹
            if epoch > max_epoch or (epoch == max_epoch and mtime > latest_mtime):
                max_epoch = epoch
                latest_mtime = mtime
                latest_file_info = {
                    'path': f,
                    'epoch': epoch,
                    'res_blocks': int(match.group(2)),
                    'hidden_units': int(match.group(3)),
                    'channels': int(match.group(4))
                }
    return latest_file_info

# ====================== Coach ç±» (å·²æ›´æ–° learn æ–¹æ³•) ======================


class Coach:
    def __init__(self, model, args):
        self.model = model
        self.args = args
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.args['learning_rate'], weight_decay=0.0001)
        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=self.args['num_epochs'])
        self.scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))
        self.training_data = deque(maxlen=self.args['data_max_size'])  # <-- ä¿®æ”¹è¿™ä¸€è¡Œ

    def train(self):
        self.model.train()
        if len(self.training_data) < self.args['batch_size']: return
        batch = random.sample(self.training_data, self.args['batch_size'])
        # ==================== æ–°å¢è¯Šæ–­æ—¥å¿— å¼€å§‹ ====================
        # ä¸ºäº†é¿å…åˆ·å±ï¼Œæˆ‘ä»¬åªæ£€æŸ¥æ‰¹æ¬¡ä¸­çš„ç¬¬ä¸€ä¸ªæ ·æœ¬
        if batch:
            print("\n[DEBUG Coach] Inspecting a sample from the training batch:")
            _sample_state, sample_policy, sample_value = batch[0]

            # æ£€æŸ¥ç­–ç•¥å‘é‡ä¸­æ˜¯å¦æœ‰éé›¶å€¼
            # np.any() ä¼šåœ¨æ‰¾åˆ°ä»»ä½•ä¸€ä¸ªéé›¶å…ƒç´ æ—¶è¿”å› True
            if np.any(sample_policy):
                print(f"  - Policy looks OK. Max probability: {np.max(sample_policy):.4f}")
            else:
                # å¦‚æœç­–ç•¥å‘é‡æ‰€æœ‰å€¼éƒ½æ˜¯0ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å±é™©çš„ä¿¡å·
                print("  - CRITICAL WARNING: Policy vector is all zeros!")

            print(f"  - Value: {sample_value:.4f}")
        # ==================== æ–°å¢è¯Šæ–­æ—¥å¿— ç»“æŸ ====================
        # ==================== æ•°æ®å¢å¼ºæ ¸å¿ƒé€»è¾‘ ====================
        augmented_batch = []
        for state, policy, value in batch:
            state_reshaped = np.array(state).reshape(self.args['num_channels'], self.args['board_size'],
                                                     self.args['board_size'])
            policy_reshaped = np.array(policy).reshape(self.args['board_size'], self.args['board_size'])

            # å¾ªç¯åº”ç”¨8ç§å¯¹ç§°å˜æ¢
            for i in range(1, 5):  # æ—‹è½¬ 0, 90, 180, 270 åº¦
                # æ—‹è½¬
                aug_state_rot = np.rot90(state_reshaped, i, axes=(1, 2))
                aug_policy_rot = np.rot90(policy_reshaped, i)
                augmented_batch.append((aug_state_rot.flatten(), aug_policy_rot.flatten(), value))

                # æ—‹è½¬åå†æ°´å¹³ç¿»è½¬
                aug_state_flipped = np.flip(aug_state_rot, axis=2)
                aug_policy_flipped = np.flip(aug_policy_rot, axis=1)
                augmented_batch.append((aug_state_flipped.flatten(), aug_policy_flipped.flatten(), value))
        # ========================================================
        # ä½¿ç”¨å¢å¼ºåçš„æ•°æ®è¿›è¡Œè®­ç»ƒ
        states, target_policies, target_values = zip(*augmented_batch)
        states = torch.tensor(np.array(states), dtype=torch.float32).to(device)
        target_policies = torch.tensor(np.array(target_policies), dtype=torch.float32).to(device)
        target_values = torch.tensor(np.array(target_values), dtype=torch.float32).unsqueeze(1).to(device)
        states = states.view(-1, self.args['num_channels'], self.args['board_size'], self.args['board_size'])
        self.optimizer.zero_grad(set_to_none=True)
        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):
            pred_log_policies, pred_values = self.model(states)
            policy_loss = -torch.sum(target_policies * pred_log_policies) / len(target_policies)
            value_loss = F.mse_loss(pred_values, target_values)
            total_loss = policy_loss + self.args['value_loss_weight'] * value_loss
        self.scaler.scale(total_loss).backward()
        self.scaler.step(self.optimizer)
        self.scaler.update()

        # è¯·ç”¨è¿™ä¸ªæ–°ç‰ˆæœ¬æ›¿æ¢æ—§çš„ learn å‡½æ•°

    def learn(self, start_epoch=1):
        for i in range(start_epoch, start_epoch + self.args['num_iterations']):
            print(f"------ è¿­ä»£è½®æ¬¡: {i} ------")

            print("æ­¥éª¤1ï¼šå¯åŠ¨çº¯C++å¼•æ“è¿›è¡Œè‡ªæˆ‘å¯¹å¼ˆ (æ­¤è¿‡ç¨‹å°†é˜»å¡)...")
            final_data_queue = queue.Queue()

            cpp_args = {k: v for k, v in self.args.items()}

            # ==================== æ–°çš„ã€æ›´å¥å£®çš„æ¨¡å‹æŸ¥æ‰¾é€»è¾‘ å¼€å§‹ ====================
            model_to_use_epoch = i - 1

            # 1. ç›´æ¥æ ¹æ®å½“å‰é…ç½®æ„å»ºæœŸæœ›çš„ã€ç²¾ç¡®çš„æ¨¡å‹æ–‡ä»¶å
            expected_res_blocks = self.args['num_res_blocks']
            expected_hidden = self.args['num_hidden']
            expected_channels = self.args['num_channels']  # <--- è·å–é€šé“æ•°
            model_to_use_path_pt = f"model_{model_to_use_epoch}_{expected_res_blocks}x{expected_hidden}_{expected_channels}c.pt"

            # 2. æ£€æŸ¥è¿™ä¸ªç²¾ç¡®çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(model_to_use_path_pt):
                # å¦‚æœä¸å­˜åœ¨ï¼Œæ‰“å°è­¦å‘Šå¹¶å›é€€åˆ°æ—§çš„æ¨¡ç³Šæœç´¢é€»è¾‘ï¼Œä»¥ç¡®ä¿æœ€å¤§å…¼å®¹æ€§
                print(f"è­¦å‘Šï¼šæ— æ³•æ‰¾åˆ°ä¸å½“å‰é…ç½®å®Œå…¨åŒ¹é…çš„æ¨¡å‹ '{model_to_use_path_pt}'ã€‚")
                print("å°†å›é€€åˆ°æ¨¡ç³Šæœç´¢æ¨¡å¼...")

                model_to_use_path_pt = None  # é‡ç½®è·¯å¾„
                pattern = re.compile(f"model_{model_to_use_epoch}_.*\\.pt")
                # å¯»æ‰¾æœ€æ–°çš„ä¸€ä¸ªæ¨¡å‹
                latest_found_time = -1
                for f in os.listdir("."):
                    if pattern.match(f):
                        file_time = os.path.getmtime(f)
                        if file_time > latest_found_time:
                            latest_found_time = file_time
                            model_to_use_path_pt = f

                if model_to_use_path_pt:
                    print(f"æ‰¾åˆ°æœ€è¿‘ä¿®æ”¹çš„åå¤‡æ¨¡å‹: '{model_to_use_path_pt}'ã€‚æ³¨æ„ï¼šè¿™å¯èƒ½ä¸C++æ•°æ®æ ¼å¼ä¸åŒ¹é…ï¼")

            # 3. å¦‚æœä»¥ä¸Šä¸¤ç§æ–¹æ³•éƒ½æ‰¾ä¸åˆ°ï¼Œå†å°è¯•æœ€åŸå§‹çš„æ–‡ä»¶åæ ¼å¼
            if model_to_use_path_pt is None:
                simple_path = f"model_{model_to_use_epoch}.pt"
                if os.path.exists(simple_path):
                    model_to_use_path_pt = simple_path
                else:
                    print(f"ã€ä¸¥é‡é”™è¯¯ã€‘æ— æ³•æ‰¾åˆ°ç¬¬ {model_to_use_epoch} è½®çš„ä»»ä½•.ptæ¨¡å‹æ–‡ä»¶ï¼ç¨‹åºé€€å‡ºã€‚")
                    return
            # ==================== æ–°çš„ã€æ›´å¥å£®çš„æ¨¡å‹æŸ¥æ‰¾é€»è¾‘ ç»“æŸ ====================

            print(f"[Python Coach] æŒ‡ç¤ºC++å¼•æ“ä½¿ç”¨æ¨¡å‹: {model_to_use_path_pt}")
            cpp_mcts_engine.run_parallel_self_play(
                model_to_use_path_pt,
                device.type == 'cuda',
                final_data_queue,
                cpp_args
            )

            print("\nè‡ªæˆ‘å¯¹å¼ˆå®Œæˆï¼æ­£åœ¨è¿›è¡Œç²¾ç»†åŒ–æ•°æ®æ”¶é›†ä¸ç­›é€‰...")
            games_processed = 0
            good_steps_collected = 0
            bad_steps_discarded = 0
            with tqdm.tqdm(total=self.args['num_selfPlay_episodes'], desc="å¤„ç†å¯¹å±€æ•°æ®") as pbar:
                while games_processed < self.args['num_selfPlay_episodes']:
                    try:
                        result = final_data_queue.get(timeout=2.0)
                        games_processed += 1
                        pbar.update(1)
                        if result.get("type") == "data":
                            game_data = result.get("data", [])
                            good_steps_from_this_game = []
                            # in learn() function
                            # ä» self.args è·å–ç­›é€‰æ ‡å¿—ï¼Œå¦‚æœconfigé‡Œæ²¡å†™ï¼Œé»˜è®¤ä¸º True (ä¿æŒåŸè¡Œä¸º)
                            enable_filtering = self.args.get('filter_zero_policy_data', True)

                            for state, policy, value in game_data:
                                # å¦‚æœå…³é—­äº†ç­›é€‰ï¼Œæˆ–è€…ç­–ç•¥å‘é‡æœ¬èº«æ˜¯æœ‰æ•ˆçš„ï¼Œåˆ™ä¿ç•™æ•°æ®
                                if not enable_filtering or np.any(policy):
                                    good_steps_from_this_game.append((state, policy, value))
                                else:
                                    bad_steps_discarded += 1
                            if good_steps_from_this_game:
                                self.training_data.extend(good_steps_from_this_game)
                                good_steps_collected += len(good_steps_from_this_game)
                    except queue.Empty:
                        print(f"\nè­¦å‘Šï¼šæ•°æ®é˜Ÿåˆ—å·²ç©ºï¼Œä½†åªå¤„ç†äº† {games_processed} å±€ã€‚")
                        break

            print(f"\næ•°æ®å¤„ç†å®Œæˆï¼")
            print(f"  æœ¬è½®å…±æ”¶é›†åˆ° {good_steps_collected} ä¸ªæœ‰æ•ˆè®­ç»ƒæ­¥éª¤ã€‚")
            print(f"  å…±ä¸¢å¼ƒäº† {bad_steps_discarded} ä¸ªæ— æ•ˆæ­¥éª¤ã€‚")
            print(f"  å½“å‰æ€»ç»éªŒåº“å¤§å°: {len(self.training_data)}")

            print("\næ­¥éª¤2ï¼šè®­ç»ƒç¥ç»ç½‘ç»œ...")
            if len(self.training_data) < self.args['batch_size']:
                print("è­¦å‘Šï¼šæœ‰æ•ˆæ•°æ®ä¸è¶³ï¼Œè·³è¿‡æœ¬è½®è®­ç»ƒã€‚å°†ä½¿ç”¨æ—§æ¨¡å‹è¿›è¡Œä¸‹ä¸€è½®è‡ªæˆ‘å¯¹å¼ˆã€‚")
                # ä¿å­˜ä¸€ä»½æ—§æ¨¡å‹ï¼Œä½†è½®æ¬¡+1ï¼Œä»¥ç¡®ä¿ä¸‹ä¸€è½®èƒ½æ‰¾åˆ°æ­£ç¡®çš„æ¨¡å‹æ–‡ä»¶
                save_model(self.model, i, self.args)
            else:
                self.model.train()
                for _ in tqdm.tqdm(range(self.args['num_epochs']), desc="è®­ç»ƒæ¨¡å‹"):
                    self.train()
                self.scheduler.step()
                save_model(self.model, i, self.args)

            clear_windows_memory()
        print(f"\nå…¨éƒ¨è®­ç»ƒè¿­ä»£å®Œæˆï¼")

    def evaluate_models(self, model1_info, model2_info):
        print(f"\n------ å¼€å§‹åˆ†ç»„è¯Šæ–­å¼è¯„ä¼° (C++ å¼•æ“é©±åŠ¨) ------")
        if not model1_info or not model2_info:
            print("è¯„ä¼°ç¼ºå°‘å¿…è¦çš„æ¨¡å‹æ–‡ä»¶ï¼Œè·³è¿‡è¯„ä¼°ã€‚")
            return

        model1_pt_path = model1_info['path'].replace('.pth', '.pt')
        model2_pt_path = model2_info['path'].replace('.pth', '.pt')

        if not os.path.exists(model1_pt_path) or not os.path.exists(model2_pt_path):
            print("è¯„ä¼°ç¼ºå°‘å¿…è¦çš„.ptæ¨¡å‹æ–‡ä»¶ï¼Œè·³è¿‡è¯„ä¼°ã€‚")
            return

        print(f"è¯„ä¼°æ¨¡å‹ (æ—§): {model1_pt_path}")
        print(f"è¯„ä¼°æ¨¡å‹ (æ–°): {model2_pt_path}")

        use_gpu = (device.type == 'cuda')
        total_games = self.args.get('num_eval_games', 100)
        games_per_side = total_games // 2
        if games_per_side == 0:
            print("è¯„ä¼°å±€æ•°è¿‡å°‘ï¼Œæ— æ³•è¿›è¡Œåˆ†ç»„è¯„ä¼°ã€‚")
            return

        eval_args = {
            # è¯„ä¼°ä¸“ç”¨å‚æ•°
            'num_eval_games': games_per_side,
            'num_eval_simulations': self.args['num_searches'],  # ä½¿ç”¨ num_searches çš„å€¼
            'num_cpu_threads': self.args.get('num_cpu_threads', 18),
            'C': self.args['C'],

            # C++å¼•æ“åˆå§‹åŒ–Gomokuå’Œæ¨¡å‹æ‰€éœ€çš„é€šç”¨å‚æ•°
            'board_size': self.args['board_size'],
            'num_rounds': self.args['num_rounds'],
            'history_steps': self.args['history_steps'],
            'num_channels': self.args['num_channels']  # C++ç«¯ä¹Ÿéœ€è¦é€šé“æ•°
        }

        # --- å®éªŒä¸€ï¼šæ–°æ¨¡å‹æ‰§å…ˆæ‰‹ (Model 2) ---
        print(f"\n[å®éªŒä¸€] æ–°æ¨¡å‹æ‰§é»‘ï¼Œè¿›è¡Œ {games_per_side} å±€...")
        results1 = cpp_mcts_engine.run_parallel_evaluation(
            model1_pt_path, model2_pt_path, use_gpu, eval_args, mode=2
        )
        new_as_p1_wins = results1.get("model2_wins", 0)
        old_as_p2_wins = results1.get("model1_wins", 0)
        draws1 = results1.get("draws", 0)

        # --- å®éªŒäºŒï¼šæ—§æ¨¡å‹æ‰§å…ˆæ‰‹ (Model 1) ---
        print(f"\n[å®éªŒäºŒ] æ—§æ¨¡å‹æ‰§é»‘ï¼Œè¿›è¡Œ {games_per_side} å±€...")
        results2 = cpp_mcts_engine.run_parallel_evaluation(
            model1_pt_path, model2_pt_path, use_gpu, eval_args, mode=1
        )
        old_as_p1_wins = results2.get("model1_wins", 0)
        new_as_p2_wins = results2.get("model2_wins", 0)
        draws2 = results2.get("draws", 0)

        # --- æ±‡æ€»å’Œåˆ†æç»“æœ ---
        total_new_wins = new_as_p1_wins + new_as_p2_wins
        total_old_wins = old_as_p1_wins + old_as_p2_wins
        total_draws = draws1 + draws2

        print("\n------ è¯Šæ–­è¯„ä¼°ç»“æœ ------")
        print(f"æ–°æ¨¡å‹æ‰§å…ˆæ‰‹æ—¶ï¼Œæˆ˜ç»© (æ–° vs æ—§ | èƒœ/è´Ÿ/å¹³): {new_as_p1_wins} / {old_as_p2_wins} / {draws1}")
        print(f"æ—§æ¨¡å‹æ‰§å…ˆæ‰‹æ—¶ï¼Œæˆ˜ç»© (æ—§ vs æ–° | èƒœ/è´Ÿ/å¹³): {old_as_p1_wins} / {new_as_p2_wins} / {draws2}")
        print("---------------------------------")

        overall_win_rate = total_new_wins / (total_games) if total_games > 0 else 0
        print(f"ç»¼åˆæˆ˜ç»© - æ–° vs æ—§ (èƒœ/è´Ÿ/å¹³): {total_new_wins} / {total_old_wins} / {total_draws}")
        print(f"æ–°æ¨¡å‹ç»¼åˆèƒœç‡: {overall_win_rate:.2%}")

        if games_per_side > 0 and (new_as_p1_wins / games_per_side) > 0.9 and (old_as_p1_wins / games_per_side) > 0.9:
            print("\nã€è¯Šæ–­ç»“è®ºã€‘: AIå·²å‘ç°å¹¶æŒæ¡äº† 'å…ˆæ‰‹å¿…èƒœ' ç­–ç•¥ã€‚")
        elif overall_win_rate > self.args.get('eval_win_rate', 0.52):
            print("\nã€è¯Šæ–­ç»“è®ºã€‘: æ–°æ¨¡å‹æœ‰æ˜¾è‘—æå‡ï¼ğŸ‘")
        else:
            print("\nã€è¯Šæ–­ç»“è®ºã€‘: æ–°æ¨¡å‹æå‡ä¸æ˜æ˜¾æˆ–æ²¡æœ‰æå‡ï¼Œå¯èƒ½é™·å…¥äº†å±€éƒ¨æœ€ä¼˜ã€‚")


# ==================== å…¨æ–°çš„ã€æ™ºèƒ½åŒ–çš„ä¸»å‡½æ•°é€»è¾‘ ====================
if __name__ == '__main__':
    # ------------------ å‚æ•°è®¡ç®—ä¸­å¿ƒ ------------------
    history_channels = (args.get('history_steps', 0) + 1) * 4
    meta_channels = 4
    total_channels = history_channels + meta_channels
    args['num_channels'] = total_channels

    print("=" * 50)
    print("MyAIChess é…ç½®åŠ è½½å®Œæˆ")
    print(f"å†å²æ­¥æ•°: {args.get('history_steps', 0)}")
    print(f"è®¡ç®—å‡ºçš„æ€»è¾“å…¥é€šé“æ•°: {args['num_channels']}")
    print("=" * 50)
    # ----------------------------------------------------

    print(f"å°†è¦ä½¿ç”¨çš„è®¾å¤‡ (ä¸»è¿›ç¨‹/è®­ç»ƒ): {device}")

    latest_model_info = find_latest_model_file()
    start_epoch = 1

    # ä½¿ç”¨åŠ¨æ€é€šé“æ•°åˆ›å»ºæ¨¡å‹å®ä¾‹
    current_model = ExtendedConnectNet(
        board_size=args['board_size'],
        num_res_blocks=args['num_res_blocks'],
        num_hidden=args['num_hidden'],
        num_channels=args['num_channels']
    ).to(device)

    model_info_before_training = None

    if latest_model_info is None:
        print("æœªæ‰¾åˆ°ä»»ä½•å·²æœ‰æ¨¡å‹ï¼Œå°†ä»ç¬¬ 1 è½®å¼€å§‹å…¨æ–°è®­ç»ƒã€‚")
        start_epoch = 1
        print("æ­£åœ¨åˆ›å»ºå¹¶ä¿å­˜åˆå§‹éšæœºæ¨¡å‹ (model_0)...")
        save_model(current_model, 0, args)
        model_info_before_training = find_latest_model_file()

    else:
        print(f"æ‰¾åˆ°æœ€æ–°æ¨¡å‹: {latest_model_info['path']} (ç¬¬ {latest_model_info['epoch']} è½®)")
        start_epoch = latest_model_info['epoch'] + 1
        model_info_before_training = latest_model_info

        config_blocks = args['num_res_blocks']
        config_hidden = args['num_hidden']
        config_channels = args['num_channels']

        # æ£€æŸ¥æ¶æ„æ—¶ï¼ŒåŒæ—¶æ£€æŸ¥é€šé“æ•°
        is_same_architecture = (latest_model_info['res_blocks'] == config_blocks and
                                latest_model_info['hidden_units'] == config_hidden and
                                latest_model_info['channels'] == config_channels)

        if is_same_architecture:
            print("æ¨¡å‹ç»“æ„ä¸å½“å‰é…ç½®ä¸€è‡´ï¼Œç›´æ¥åŠ è½½æƒé‡ç»§ç»­è®­ç»ƒã€‚")
            try:
                current_model.load_state_dict(torch.load(latest_model_info['path'], map_location=device))
                print("æƒé‡åŠ è½½æˆåŠŸï¼")
            except Exception as e:
                print(f"åŠ è½½æƒé‡å¤±è´¥: {e}ï¼Œå°†ä»éšæœºæƒé‡å¼€å§‹ã€‚")
                start_epoch = 1
        else:
            print("æ¨¡å‹ç»“æ„ä¸å½“å‰é…ç½®ä¸ä¸€è‡´ï¼Œå°†æ‰§è¡Œè‡ªåŠ¨è¿ç§»å­¦ä¹ ã€‚")
            print(
                f"  æ—§ç»“æ„: {latest_model_info['res_blocks']} res_blocks, {latest_model_info['hidden_units']} hidden, {latest_model_info.get('channels', 'N/A')} channels")
            print(f"  æ–°ç»“æ„: {config_blocks} res_blocks, {config_hidden} hidden, {config_channels} channels")
            try:
                current_model = transfer_weights(current_model, latest_model_info['path'])

                print("ä¸ºè¿ç§»å­¦ä¹ åçš„æ–°æ¨¡å‹åˆ›å»ºåŒ¹é…çš„ .pt æ–‡ä»¶...")
                save_model(current_model, latest_model_info['epoch'], args)

                # vvvvvvvv ã€è¯·åŠ¡å¿…ç¡®è®¤å¢åŠ äº†æ­¤æ®µä»£ç ã€‘ vvvvvvvv
                # åœ¨ä¿å­˜äº†è¿ç§»åçš„æ–°æ¨¡å‹åï¼Œå¿…é¡»ç«‹å³é‡æ–°æŸ¥æ‰¾å¹¶æ›´æ–°è¯„ä¼°åŸºå‡†ï¼Œ
                # ä»¥ç¡®ä¿ model_info_before_training æŒ‡å‘çš„æ˜¯è¿™ä¸ªæ–°æ¶æ„çš„æ¨¡å‹ã€‚
                print("...æ›´æ–°è¯„ä¼°åŸºå‡†ä¸ºæ–°æ¶æ„çš„æ¨¡å‹...")
                model_info_before_training = find_latest_model_file()
                # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

            except Exception as e:
                print(f"è¿ç§»å­¦ä¹ å¤±è´¥: {e}ï¼Œå°†ä»éšæœºæƒé‡å¼€å§‹è®­ç»ƒæ–°ç»“æ„æ¨¡å‹ã€‚")

    coach = Coach(current_model, args)
    coach.learn(start_epoch=start_epoch)

    model_info_after_training = find_latest_model_file()

    if model_info_before_training and model_info_after_training and \
            model_info_before_training['path'] != model_info_after_training['path']:
        coach.evaluate_models(model_info_before_training, model_info_after_training)
    else:
        print("\næœªè¿›è¡Œæœ‰æ•ˆçš„æ–°ä¸€è½®è®­ç»ƒæˆ–æœªæ‰¾åˆ°æ—§æ¨¡å‹ï¼Œè·³è¿‡è¯„ä¼°ã€‚")

    print("\nè®­ç»ƒå…¨éƒ¨å®Œæˆï¼Œæ­£åœ¨æ‰‹åŠ¨æ¸…ç†å†…å­˜...")
    if 'coach' in locals() and hasattr(coach, 'training_data'):
        coach.training_data.clear()
        print("ç»éªŒå›æ”¾æ± å·²æ¸…ç©ºã€‚")
    import gc

    gc.collect()
    print("å†…å­˜æ¸…ç†å®Œæˆã€‚ç¨‹åºå³å°†é€€å‡ºã€‚")
